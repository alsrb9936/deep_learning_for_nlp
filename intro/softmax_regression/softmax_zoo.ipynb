{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16) (101, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xy = np.loadtxt('/Users/jangmingyu/ps/deep_learning_for_nlp/intro/softmax_regression/dataset/data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "nb_classes = 7\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#테스트 데이터, 훈련 데이터 구별\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(x_data, y_data,train_size=0.8,random_state=1)\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train,nb_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test,nb_classes)\n",
    "\n",
    "print(Y_train[:5])\n",
    "print(Y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 16:29:26.808018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/80 [===========================>..] - ETA: 0s - loss: 2.6720 - accuracy: 0.1200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 16:29:28.392849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 11ms/step - loss: 2.6528 - accuracy: 0.1375 - val_loss: 2.4444 - val_accuracy: 0.1750\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 2.2662 - accuracy: 0.2125 - val_loss: 2.0706 - val_accuracy: 0.2250\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 1.9383 - accuracy: 0.2625 - val_loss: 1.7800 - val_accuracy: 0.2875\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 1.6696 - accuracy: 0.4125 - val_loss: 1.5523 - val_accuracy: 0.5375\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 1.4647 - accuracy: 0.5500 - val_loss: 1.3662 - val_accuracy: 0.5875\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 1.3050 - accuracy: 0.6000 - val_loss: 1.2278 - val_accuracy: 0.6250\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 1.1829 - accuracy: 0.6500 - val_loss: 1.1194 - val_accuracy: 0.6500\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 1.0786 - accuracy: 0.6750 - val_loss: 1.0287 - val_accuracy: 0.6875\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.9954 - accuracy: 0.7000 - val_loss: 0.9515 - val_accuracy: 0.7000\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.9259 - accuracy: 0.7000 - val_loss: 0.8866 - val_accuracy: 0.7125\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.8620 - accuracy: 0.8000 - val_loss: 0.8273 - val_accuracy: 0.8750\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.8080 - accuracy: 0.8875 - val_loss: 0.7779 - val_accuracy: 0.8875\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.7617 - accuracy: 0.8875 - val_loss: 0.7350 - val_accuracy: 0.8875\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.7188 - accuracy: 0.8875 - val_loss: 0.6937 - val_accuracy: 0.8875\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6803 - accuracy: 0.8875 - val_loss: 0.6573 - val_accuracy: 0.8875\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6462 - accuracy: 0.8875 - val_loss: 0.6256 - val_accuracy: 0.8875\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6138 - accuracy: 0.8875 - val_loss: 0.5957 - val_accuracy: 0.8875\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5868 - accuracy: 0.8875 - val_loss: 0.5694 - val_accuracy: 0.8875\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5611 - accuracy: 0.8875 - val_loss: 0.5440 - val_accuracy: 0.8875\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5368 - accuracy: 0.8875 - val_loss: 0.5212 - val_accuracy: 0.8875\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5141 - accuracy: 0.8875 - val_loss: 0.4999 - val_accuracy: 0.8875\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4937 - accuracy: 0.8875 - val_loss: 0.4799 - val_accuracy: 0.8875\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4742 - accuracy: 0.8875 - val_loss: 0.4620 - val_accuracy: 0.8875\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4565 - accuracy: 0.8875 - val_loss: 0.4441 - val_accuracy: 0.9000\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4400 - accuracy: 0.8875 - val_loss: 0.4277 - val_accuracy: 0.8875\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4232 - accuracy: 0.8875 - val_loss: 0.4126 - val_accuracy: 0.9125\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4085 - accuracy: 0.9000 - val_loss: 0.3983 - val_accuracy: 0.9125\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3950 - accuracy: 0.9125 - val_loss: 0.3846 - val_accuracy: 0.9125\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3813 - accuracy: 0.9125 - val_loss: 0.3712 - val_accuracy: 0.9125\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3685 - accuracy: 0.9125 - val_loss: 0.3603 - val_accuracy: 0.9250\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3569 - accuracy: 0.9250 - val_loss: 0.3479 - val_accuracy: 0.9250\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3451 - accuracy: 0.9250 - val_loss: 0.3362 - val_accuracy: 0.9250\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3338 - accuracy: 0.9250 - val_loss: 0.3257 - val_accuracy: 0.9250\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3240 - accuracy: 0.9375 - val_loss: 0.3169 - val_accuracy: 0.9375\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3141 - accuracy: 0.9375 - val_loss: 0.3062 - val_accuracy: 0.9375\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3048 - accuracy: 0.9375 - val_loss: 0.2975 - val_accuracy: 0.9375\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2957 - accuracy: 0.9375 - val_loss: 0.2887 - val_accuracy: 0.9375\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2872 - accuracy: 0.9375 - val_loss: 0.2803 - val_accuracy: 0.9375\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2795 - accuracy: 0.9375 - val_loss: 0.2723 - val_accuracy: 0.9375\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2708 - accuracy: 0.9375 - val_loss: 0.2643 - val_accuracy: 0.9375\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2636 - accuracy: 0.9375 - val_loss: 0.2573 - val_accuracy: 0.9375\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2563 - accuracy: 0.9375 - val_loss: 0.2500 - val_accuracy: 0.9375\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2491 - accuracy: 0.9375 - val_loss: 0.2432 - val_accuracy: 0.9375\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2424 - accuracy: 0.9375 - val_loss: 0.2366 - val_accuracy: 0.9500\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2361 - accuracy: 0.9375 - val_loss: 0.2309 - val_accuracy: 0.9500\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2308 - accuracy: 0.9500 - val_loss: 0.2251 - val_accuracy: 0.9500\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2241 - accuracy: 0.9500 - val_loss: 0.2185 - val_accuracy: 0.9500\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2177 - accuracy: 0.9500 - val_loss: 0.2133 - val_accuracy: 0.9625\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2136 - accuracy: 0.9625 - val_loss: 0.2078 - val_accuracy: 0.9625\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2073 - accuracy: 0.9625 - val_loss: 0.2030 - val_accuracy: 0.9625\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2022 - accuracy: 0.9625 - val_loss: 0.1972 - val_accuracy: 0.9625\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.9625 - val_loss: 0.1929 - val_accuracy: 0.9625\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1926 - accuracy: 0.9625 - val_loss: 0.1879 - val_accuracy: 0.9625\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9625 - val_loss: 0.1835 - val_accuracy: 0.9625\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1830 - accuracy: 0.9625 - val_loss: 0.1790 - val_accuracy: 0.9625\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1788 - accuracy: 0.9625 - val_loss: 0.1747 - val_accuracy: 0.9625\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.9625 - val_loss: 0.1705 - val_accuracy: 0.9625\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1705 - accuracy: 0.9625 - val_loss: 0.1664 - val_accuracy: 0.9625\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1665 - accuracy: 0.9625 - val_loss: 0.1625 - val_accuracy: 0.9625\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1632 - accuracy: 0.9625 - val_loss: 0.1592 - val_accuracy: 0.9625\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1588 - accuracy: 0.9625 - val_loss: 0.1550 - val_accuracy: 0.9625\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9625 - val_loss: 0.1515 - val_accuracy: 0.9875\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9625 - val_loss: 0.1481 - val_accuracy: 0.9875\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1488 - accuracy: 0.9875 - val_loss: 0.1448 - val_accuracy: 0.9875\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1450 - accuracy: 0.9875 - val_loss: 0.1416 - val_accuracy: 0.9875\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1417 - accuracy: 0.9875 - val_loss: 0.1384 - val_accuracy: 0.9875\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9875 - val_loss: 0.1356 - val_accuracy: 0.9875\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1359 - accuracy: 0.9875 - val_loss: 0.1324 - val_accuracy: 0.9875\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1327 - accuracy: 0.9875 - val_loss: 0.1295 - val_accuracy: 0.9875\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1297 - accuracy: 0.9875 - val_loss: 0.1266 - val_accuracy: 0.9875\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.9875 - val_loss: 0.1239 - val_accuracy: 0.9875\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9875 - val_loss: 0.1212 - val_accuracy: 0.9875\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1215 - accuracy: 0.9875 - val_loss: 0.1186 - val_accuracy: 0.9875\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1191 - accuracy: 0.9875 - val_loss: 0.1161 - val_accuracy: 0.9875\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1163 - accuracy: 0.9875 - val_loss: 0.1138 - val_accuracy: 0.9875\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9875 - val_loss: 0.1115 - val_accuracy: 0.9875\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1123 - accuracy: 0.9875 - val_loss: 0.1092 - val_accuracy: 0.9875\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1090 - accuracy: 0.9875 - val_loss: 0.1067 - val_accuracy: 0.9875\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1071 - accuracy: 0.9875 - val_loss: 0.1044 - val_accuracy: 0.9875\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1046 - accuracy: 0.9875 - val_loss: 0.1025 - val_accuracy: 0.9875\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=nb_classes,input_dim=16,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "his = model.fit(X_train, Y_train, epochs=200, batch_size=1, validation_data=(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 출력해보자\n",
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, len(his.history['accuracy'])+1)\n",
    "\n",
    "plt.plot(epochs, his.history['loss'])\n",
    "plt.plot(epochs, his.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0879 - accuracy: 0.9524\n",
      "\n",
      " 테스트 정확도:  0.9524\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: \",round(model.evaluate(X_test, Y_test)[1],4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tfp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40877e6eef2460e156147e89f2e2b0097afbc1cf4c1dcda922187c7441857d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
