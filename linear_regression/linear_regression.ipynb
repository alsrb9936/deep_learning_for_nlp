{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(4.0)\n",
    "b = tf.Variable(2.0)\n",
    "learning_rate = 0.01\n",
    "training_step = 300\n",
    "display_step = 10\n",
    "\n",
    "# 데이터 \n",
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "Y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설과 손실함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(x):\n",
    "    return W*x + b\n",
    "\n",
    "def mse(pred,true):\n",
    "    # y 예측값과 y 값 차의 제곱 평균 -> 평균 제곱 오차\n",
    "    return tf.reduce_mean(tf.square(pred - true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimzer = 경사하강법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 약 300번에 걸쳐 경사하강법 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  10 | W의 값: 10.3475 | b의 값: 2.918 | cost : 2.007087\n",
      "epoch:  20 | W의 값: 10.3612 | b의 값: 2.833 | cost : 1.932228\n",
      "epoch:  30 | W의 값: 10.3742 | b의 값: 2.751 | cost : 1.863295\n",
      "epoch:  40 | W의 값: 10.3866 | b의 값: 2.672 | cost : 1.799810\n",
      "epoch:  50 | W의 값: 10.3986 | b의 값: 2.597 | cost : 1.741337\n",
      "epoch:  60 | W의 값: 10.4101 | b의 값: 2.525 | cost : 1.687485\n",
      "epoch:  70 | W의 값: 10.4211 | b의 값: 2.456 | cost : 1.637895\n",
      "epoch:  80 | W의 값: 10.4317 | b의 값: 2.389 | cost : 1.592217\n",
      "epoch:  90 | W의 값: 10.4418 | b의 값: 2.325 | cost : 1.550151\n",
      "epoch: 100 | W의 값: 10.4516 | b의 값: 2.264 | cost : 1.511410\n",
      "epoch: 110 | W의 값: 10.4609 | b의 값: 2.205 | cost : 1.475731\n",
      "epoch: 120 | W의 값: 10.4699 | b의 값: 2.149 | cost : 1.442866\n",
      "epoch: 130 | W의 값: 10.4785 | b의 값: 2.095 | cost : 1.412601\n",
      "epoch: 140 | W의 값: 10.4867 | b의 값: 2.043 | cost : 1.384729\n",
      "epoch: 150 | W의 값: 10.4947 | b의 값: 1.993 | cost : 1.359059\n",
      "epoch: 160 | W의 값: 10.5023 | b의 값: 1.945 | cost : 1.335419\n",
      "epoch: 170 | W의 값: 10.5096 | b의 값: 1.899 | cost : 1.313645\n",
      "epoch: 180 | W의 값: 10.5166 | b의 값: 1.855 | cost : 1.293593\n",
      "epoch: 190 | W의 값: 10.5233 | b의 값: 1.812 | cost : 1.275126\n",
      "epoch: 200 | W의 값: 10.5298 | b의 값: 1.772 | cost : 1.258113\n",
      "epoch: 210 | W의 값: 10.5360 | b의 값: 1.733 | cost : 1.242449\n",
      "epoch: 220 | W의 값: 10.5419 | b의 값: 1.696 | cost : 1.228019\n",
      "epoch: 230 | W의 값: 10.5476 | b의 값:  1.66 | cost : 1.214736\n",
      "epoch: 240 | W의 값: 10.5531 | b의 값: 1.625 | cost : 1.202496\n",
      "epoch: 250 | W의 값: 10.5583 | b의 값: 1.592 | cost : 1.191227\n",
      "epoch: 260 | W의 값: 10.5634 | b의 값:  1.56 | cost : 1.180850\n",
      "epoch: 270 | W의 값: 10.5682 | b의 값:  1.53 | cost : 1.171290\n",
      "epoch: 280 | W의 값: 10.5728 | b의 값: 1.501 | cost : 1.162482\n",
      "epoch: 290 | W의 값: 10.5773 | b의 값: 1.473 | cost : 1.154379\n",
      "epoch: 300 | W의 값: 10.5816 | b의 값: 1.446 | cost : 1.146909\n"
     ]
    }
   ],
   "source": [
    "for step in range(1, training_step+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 현재 파라미터에 기반한 입력값 x에 대한 예측값 y_pred\n",
    "        y_pred = hypothesis(X)\n",
    "        \n",
    "        # 평균 제곱 오차\n",
    "        cost = mse(y_pred,Y)\n",
    "        \n",
    "    # 손실함수에 대한 파라미터 미분값 계산 (현재 W와 b)\n",
    "    gradients = tape.gradient(cost,[W,b])\n",
    "    \n",
    "    # 파라미터 업데이터\n",
    "    optimizer.apply_gradients(zip(gradients, [W,b]))\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        print(\"epoch: {:3} | W의 값: {:5.4f} | b의 값: {:5.4} | cost : {:5.6f}\".format(step, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.48135  54.353718 59.64451  64.9353  ]\n"
     ]
    }
   ],
   "source": [
    "### 임의의 값 테스트\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
